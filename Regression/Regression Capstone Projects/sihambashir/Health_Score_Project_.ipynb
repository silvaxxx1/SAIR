{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f34466",
   "metadata": {},
   "source": [
    "# ğŸ  Ù…Ø´Ø±ÙˆØ¹: Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ø±Ø¬Ø© Ø§Ù„ØµØ­Ø© (Health Score Prediction) â€” Ø¨ØµÙŠØºØ© Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø©\n",
    "**ÙˆØµÙ:** Ù…Ø´Ø±ÙˆØ¹ Ù…Ù†Ø¸Ù‘Ù… Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ù„ØªÙ†Ø¨Ø¤ â€œHealth Scoreâ€ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù†Ø­Ø¯Ø§Ø±: Decision Tree, Random Forest, XGBoost, LightGBM.\n",
    "\n",
    "\n",
    "**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„:**\n",
    "- ÙƒÙ„ Ø®Ù„ÙŠØ© Ù…Ø³ØªÙ‚Ù„Ø© ÙˆÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„Ù‡Ø§ Ø¹Ù„Ù‰ Ø­Ø¯Ø©.\n",
    "- Ø§Ù„Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ ÙƒÙˆØ¯ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙ†ÙÙŠØ° ÙÙŠ Python (Jupyter / Colab).\n",
    "- Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ù `best_model.pkl` Ùˆ`scaler.pkl` Ùˆ`encoders.pkl` Ùˆ`regression_models_results.csv` Ø¨Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d479085",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© (Environment Setup)\n",
    "Ø´Ø±Ø­: Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ¶Ø¨Ø· Ø§Ù„Ø¨ÙŠØ¦Ø©. Ø´ØºÙ‘Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ© Ø£ÙˆÙ„Ù‹Ø§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Ù…ÙƒØªØ¨Ø§Øª scikit-learn Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Ù†Ù…Ø§Ø°Ø¬\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Ù…ÙƒØªØ¨Ø§Øª Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© (XGBoost, LightGBM)\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    XGBRegressor = None\n",
    "    print('âš ï¸ xgboost ØºÙŠØ± Ù…Ø«Ø¨Øª â€” Ù„ØªØ«Ø¨ÙŠØª: pip install xgboost')\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception:\n",
    "    LGBMRegressor = None\n",
    "    print('âš ï¸ lightgbm ØºÙŠØ± Ù…Ø«Ø¨Øª â€” Ù„ØªØ«Ø¨ÙŠØª: pip install lightgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937d9c2",
   "metadata": {},
   "source": [
    "## ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Load Data)\n",
    "Ø´Ø±Ø­: Ø¶ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª `synthetic_health_data.csv` ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù€ NotebookØŒ Ø«Ù… Ø´ØºÙ‘Ù„ Ø§Ù„Ø®Ù„ÙŠØ© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81323dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"synthetic_health_data.csv\")\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"âŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {DATA_PATH.resolve()}\\nØ£Ø±ÙÙØ¹ Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø­Ø¯Ù‘Ø« Ù…Ø³Ø§Ø± DATA_PATH.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª â€” Ø§Ù„Ø´ÙƒÙ„:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dd2dc",
   "metadata": {},
   "source": [
    "## ğŸ§  ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙŠØ²Ø§Øª (Feature Engineering)\n",
    "Ø´Ø±Ø­: Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¹Ù…ÙˆØ¯ `Health_Score` Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ØŒ Ø³Ù†Ù†Ø´Ø¦Ù‡ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙˆØ²Ø§Ù† Ù…Ø¨Ø¯Ø¦ÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„. Ø¨Ø¹Ø¯Ù‡Ø§ Ù†Ø¹Ø±Ø¶ ÙˆØµÙÙ‹Ø§ Ø¥Ø­ØµØ§Ø¦ÙŠÙ‹Ø§ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ac443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥Ù†Ø´Ø§Ø¡ Health_Score Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if \"Health_Score\" not in df.columns:\n",
    "    print(\"âš™ï¸ Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Health_Score ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙˆØ²Ø§Ù† Ù…Ø¨Ø¯Ø¦ÙŠØ©...\")\n",
    "    # ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¨Ø­Ø³Ø¨ Ø®Ø¨Ø±ØªÙƒ Ø£Ùˆ Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù…Ø¬Ø§Ù„\n",
    "    weights = {\n",
    "        \"Sleep_Hours\": 0.20,\n",
    "        \"Diet_Quality\": 0.25,\n",
    "        \"Activity_Level\": 0.25,\n",
    "        \"Stress_Level\": -0.15,\n",
    "        \"Blood_Pressure\": -0.10,\n",
    "        \"Age\": -0.05\n",
    "    }\n",
    "    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
    "    missing = [c for c in weights.keys() if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Health_Score: {missing}\")\n",
    "    df[\"Health_Score\"] = sum(df[col] * w for col, w in weights.items())\n",
    "    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ø¬ÙŠÙ… Ø¥Ù„Ù‰ Ù†Ø·Ø§Ù‚ 0-100\n",
    "    df[\"Health_Score\"] = 100 * (df[\"Health_Score\"] - df[\"Health_Score\"].min()) / (df[\"Health_Score\"].max() - df[\"Health_Score\"].min())\n",
    "else:\n",
    "    print(\"â„¹ï¸ Ø¹Ù…ÙˆØ¯ Health_Score Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ â€” Ø³Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙƒÙ…Ø§ Ù‡Ùˆ.\")\n",
    "\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722af71",
   "metadata": {},
   "source": [
    "## ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠ (EDA)\n",
    "Ø´Ø±Ø­: Ø³Ù†Ø³ØªØ¹Ù…Ù„ Ø±Ø³ÙˆÙ…Ø§Øª ØªÙˆØ¶ÙŠØ­ÙŠØ© Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª ÙˆØ§Ù„ØªÙˆØ²ÙŠØ¹. (Ù…Ù„Ø§Ø­Ø¸Ø©: Ù†Ø³ØªØ®Ø¯Ù… matplotlib Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³ÙˆÙ… Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø¨ÙŠØ¦Ø§Øª Ù…Ø®ØªÙ„ÙØ©)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e77058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· (correlation matrix) ÙˆØ±Ø³Ù… Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… matplotlib\n",
    "corr = df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cax = ax.matshow(corr, cmap='coolwarm')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticks(range(len(corr.columns)))\n",
    "ax.set_yticks(range(len(corr.columns)))\n",
    "ax.set_xticklabels(corr.columns, rotation=90)\n",
    "ax.set_yticklabels(corr.columns)\n",
    "plt.title(\"Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª\", pad=20)\n",
    "plt.show()\n",
    "\n",
    "# ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù‡Ø¯Ù\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.hist(df['Health_Score'].dropna(), bins=30)\n",
    "ax.set_title('ØªÙˆØ²ÙŠØ¹ Health_Score')\n",
    "ax.set_xlabel('Health_Score')\n",
    "ax.set_ylabel('Ø§Ù„Ø¹Ø¯Ø¯')\n",
    "plt.show()\n",
    "\n",
    "# Ø±Ø³Ù… Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø¨Ø¹Ø¶ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ùˆ Health_Score\n",
    "pairs = [('Sleep_Hours', 'Health_Score'), ('Activity_Level', 'Health_Score'), ('Stress_Level', 'Health_Score')]\n",
    "for xcol, ycol in pairs:\n",
    "    if xcol in df.columns and ycol in df.columns:\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        ax.scatter(df[xcol], df[ycol], alpha=0.6)\n",
    "        ax.set_xlabel(xcol)\n",
    "        ax.set_ylabel(ycol)\n",
    "        ax.set_title(f'{ycol} Ù…Ù‚Ø§Ø¨Ù„ {xcol}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc45d6",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Ø§Ù„ØªØ±Ù…ÙŠØ² (Encoding) ÙˆØ§Ù„Ù‚ÙŠØ§Ø³ (Scaling)\n",
    "Ø´Ø±Ø­: ØªØ±Ù…ÙŠØ² Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø«Ù… Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… StandardScaler. Ø³Ù†Ø­ÙØ¸ Ø§Ù„Ù€ encoders Ùˆ scaler Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø´Ø±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Health_Score'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "encoders = {}\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        encoders[col] = le\n",
    "\n",
    "# Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø§Ù„Ø¨Ø³ÙŠØ· (Ø¥Ù† ÙˆØ¬Ø¯Øª) â€” Ù‡Ù†Ø§ Ù†Ø¹ÙˆØ¶ Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø· Ù„Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ©\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Ø­ÙØ¸ Ù…Ø¤Ù‚Øª Ù„Ù„Ù€ encoders (Ù„Ø§ ØªÙ‚Ù… Ø¨Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø­ØªÙ‰ Ù†Ø¹Ø±Ù Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬)\n",
    "# joblib.dump(encoders, 'encoders_partial.pkl')\n",
    "print('âœ… Ø§Ù„ØªØ±Ù…ÙŠØ² ÙˆØ§Ù„Ù‚ÙŠØ§Ø³ Ø¬Ø§Ù‡Ø²Ø§Ù†. Ø´ÙƒÙ„ X:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc6897",
   "metadata": {},
   "source": [
    "## ğŸ”€ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Train/Test Split)\n",
    "Ø´Ø±Ø­: Ù†Ù‚Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© ØªØ¯Ø±ÙŠØ¨ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø§Ø®ØªØ¨Ø§Ø± (80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f542437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print('âœ… Training shape:', X_train.shape, 'Testing shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675e654",
   "metadata": {},
   "source": [
    "## âš™ï¸ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Hyperparameter Tuning)\n",
    "Ø´Ø±Ø­: Ø³Ù†Ø³ØªØ®Ø¯Ù… `RandomizedSearchCV` Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ â€” Ø§Ù„ÙØ±Ø§ØºØ§Øª Ù‡Ù†Ø§ Ø£ÙˆØ³Ø¹ Ù‚Ù„ÙŠÙ„Ù‹Ø§ Ù„ØªØ¹ÙƒØ³ Ù…Ù†Ù‡Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58880f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "def run_random_search(name, estimator, param_dist, n_iter=30, cv=3):\n",
    "    print(f\"\\nğŸ”§ Ø¨Ø¯Ø¡ Ø§Ù„Ø¶Ø¨Ø·: {name}\")\n",
    "    rs = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=n_iter,\n",
    "                            scoring='r2', cv=cv, random_state=42, n_jobs=-1, verbose=0)\n",
    "    rs.fit(X_train, y_train)\n",
    "    best = rs.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"âœ… {name} â€” R2_test: {r2:.4f} | MAE_test: {mae:.4f}\")\n",
    "    print('ğŸ”§ Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª (best_params):', rs.best_params_)\n",
    "    return {'name': name, 'model': best, 'r2': r2, 'mae': mae, 'best_params': rs.best_params_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba310d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Decision Tree\n",
    "dt_params = {\n",
    "    'max_depth': [3, 5, 8, 12, None],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 6),\n",
    "    'criterion': ['squared_error', 'friedman_mse']\n",
    "}\n",
    "results.append(run_random_search('DecisionTree', DecisionTreeRegressor(random_state=42), dt_params, n_iter=30))\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [5, 8, 12, None],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 6),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "results.append(run_random_search('RandomForest', RandomForestRegressor(random_state=42), rf_params, n_iter=30))\n",
    "\n",
    "# XGBoost (if available)\n",
    "if XGBRegressor is not None:\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 8],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "    results.append(run_random_search('XGBoost', XGBRegressor(eval_metric='rmse', random_state=42), xgb_params, n_iter=30))\n",
    "else:\n",
    "    print('âš ï¸ ØªØ®Ø·ÙŠ XGBoost â€” Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒØªØ¨Ø©.')\n",
    "\n",
    "# LightGBM (if available)\n",
    "if LGBMRegressor is not None:\n",
    "    lgb_params = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'num_leaves': [15, 31, 63],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'min_data_in_leaf': [10, 20, 40]\n",
    "    }\n",
    "    results.append(run_random_search('LightGBM', LGBMRegressor(random_state=42), lgb_params, n_iter=30))\n",
    "else:\n",
    "    print('âš ï¸ ØªØ®Ø·ÙŠ LightGBM â€” Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒØªØ¨Ø©.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb4ed6",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡\n",
    "Ø´Ø±Ø­: Ù†Ù„Ø®Ù‘Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„ ÙˆÙ†Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø§Øª RÂ² Ùˆ MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame([{\n",
    "    'Model': r['name'],\n",
    "    'R2_test': r['r2'],\n",
    "    'MAE_test': r['mae'],\n",
    "    'best_params': r['best_params']\n",
    "} for r in results])\n",
    "\n",
    "res_df = res_df.sort_values('R2_test', ascending=False).reset_index(drop=True)\n",
    "display(res_df[['Model','R2_test','MAE_test']])\n",
    "\n",
    "# Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© R2\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.bar(res_df['Model'], res_df['R2_test'])\n",
    "ax.set_ylabel('R2 (Test)')\n",
    "ax.set_title('Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­Ø³Ø¨ R2')\n",
    "plt.show()\n",
    "\n",
    "# Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© MAE\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.bar(res_df['Model'], res_df['MAE_test'])\n",
    "ax.set_ylabel('MAE (Test)')\n",
    "ax.set_title('Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­Ø³Ø¨ MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f9663",
   "metadata": {},
   "source": [
    "## ğŸ† Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„ ÙˆØ­ÙØ¸Ù‡\n",
    "Ø´Ø±Ø­: Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø¹Ù„Ù‰ R2 Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø«Ù… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø­ÙˆÙ‘Ù„ ÙˆØ§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª ÙˆÙ†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¶Ø¨Ø·."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32cef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = res_df.loc[res_df['R2_test'].idxmax()]\n",
    "best_name = best_row['Model']\n",
    "best_model_obj = next(r['model'] for r in results if r['name'] == best_name)\n",
    "\n",
    "print(f\"ğŸ† Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {best_name} â€” R2_test = {best_row['R2_test']:.4f}\")\n",
    "\n",
    "joblib.dump(best_model_obj, 'best_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(encoders, 'encoders.pkl')\n",
    "res_df.to_csv('regression_models_results.csv', index=False)\n",
    "print('âœ… Ø­ÙØ¸Øª: best_model.pkl, scaler.pkl, encoders.pkl, regression_models_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bdcc0",
   "metadata": {},
   "source": [
    "## ğŸ“ Ø§Ù„Ø®Ù„Ø§ØµØ© (Summary & Insights)\n",
    "- Ù„Ø®Øµ Ù‡Ù†Ø§ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ ØªÙÙˆÙ‚ØŒ Ù‚ÙŠÙ… RÂ² ÙˆMAEØŒ ÙˆÙ…Ø§ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙŠ Ø§ÙƒØªØ´ÙÙ†Ø§Ù‡Ø§.\n",
    "- Ø§Ø°ÙƒØ± ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ©: Ù…Ø«Ù„ Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©ØŒ Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…ØªÙˆÙ‚Ø¹Ø© Ø§Ù„ØªØ£Ø«ÙŠØ±ØŒ Ø£Ùˆ Ø®Ø·ÙˆØ§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ (feature engineering, ensemble, stacking)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1b183",
   "metadata": {},
   "source": [
    "## ğŸš€ ØªØ­Ø¶ÙŠØ± Ù„Ù„Ù†Ø´Ø± (Deployment Preparation)\n",
    "Ø´Ø±Ø­ Ù…Ø®ØªØµØ±: ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø´Ø± `best_model.pkl` Ù…Ø¹ `scaler.pkl` Ùˆ`encoders.pkl` Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit Ø£Ùˆ Flask. ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù…Ø«Ø§Ù„ Ù…Ø¨Ø³Ø· Ù„ÙƒÙˆØ¯ Streamlit Ù„Ù„Ù†Ø´Ø±:\n",
    "\n",
    "```python\n",
    "# streamlit_app.py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load('best_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "encoders = joblib.load('encoders.pkl')\n",
    "\n",
    "st.title('Health Score Predictor')\n",
    "# ... Ø¥Ø¶Ø§ÙØ© ÙˆØ§Ø¬Ù‡Ø© Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø«Ù… Ø§Ù„ØªÙ†Ø¨Ø¤\n",
    "```\n",
    "\n",
    "â€” Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
