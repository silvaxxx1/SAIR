{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Spaceship Titanic: Your First Interstellar ML Mission!\n",
    "\n",
    "## ğŸŒŒ Welcome to the Future of Space Travel!\n",
    "\n",
    "Imagine you're a data scientist in the year 2912, where interstellar travel is common. The Spaceship Titanic, an interstellar passenger liner, met a similar fate as its historical counterpart. Your mission: **predict which passengers were transported to an alternate dimension** during the spaceship's collision with a spacetime anomaly!\n",
    "\n",
    "### ğŸ¯ Your Mission Objectives:\n",
    "\n",
    "1. **ğŸ•µï¸ Investigate** the passenger data to find clues about who survived\n",
    "2. **ğŸ”§ Build** a machine learning model that can predict survival\n",
    "3. **ğŸš€ Compete** on Kaggle and climb the leaderboard\n",
    "4. **ğŸ“Š Learn** production-ready ML workflows used by industry professionals\n",
    "\n",
    "> ğŸ® **Think of this as a detective game** - you're looking for patterns in the data that reveal who was \"transported\" and who wasn't!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š What You'll Learn Today\n",
    "\n",
    "| Skill | Why It Matters |\n",
    "|-------|----------------|\n",
    "| **Real-world Data Cleaning** | Real data is messy - learn to handle missing values and outliers |\n",
    "| **Feature Engineering** | Create new features that help your model make better predictions |\n",
    "| **Multiple ML Models** | Compare different algorithms to find the best one |\n",
    "| **Hyperparameter Tuning** | Fine-tune your model like a professional |\n",
    "| **Model Evaluation** | Understand if your model is actually good |\n",
    "| **Kaggle Submission** | Compete with data scientists worldwide |\n",
    "\n",
    "> ğŸ’¡ **Pro Tip:** Don't just copy the code - try to understand WHY each step matters. This will make you a better data scientist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ› ï¸ Mission Control: Setting Up Your Tools\n",
    "\n",
    "Before we launch into space, let's make sure we have all our tools ready! Think of this as preparing your spaceship for the journey.\n",
    "\n",
    "### Why This Setup Matters:\n",
    "- **Reproducibility**: So you (or others) can get the same results later\n",
    "- **Organization**: Keeping your work clean and professional\n",
    "- **Tracking**: MLflow will be our \"mission log\" tracking everything we do\n",
    "\n",
    "> ğŸ¯ **Learning Goal**: Professional data scientists always set up their environment properly - it saves time and prevents errors later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ LAUNCH SEQUENCE: Importing our space exploration tools!\n",
    "\n",
    "# First, let's silence any annoying warning beeps\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ğŸŒŒ Core navigation systems (essential libraries)\n",
    "import numpy as np  # For mathematical calculations\n",
    "import pandas as pd  # For data manipulation - our main tool!\n",
    "import matplotlib.pyplot as plt  # For creating visual charts\n",
    "import seaborn as sns  # For prettier, more informative charts\n",
    "from scipy import stats  # For statistical analysis\n",
    "import joblib  # For saving our trained models\n",
    "import json  # For storing model information\n",
    "from datetime import datetime  # For timestamps\n",
    "import os  # For file operations\n",
    "import time  # For timing our experiments\n",
    "\n",
    "# ğŸ¤– Machine learning crew members\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# ğŸ“Š Mission control dashboard (MLflow for tracking)\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# ğŸ¨ Enhanced visualization tools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(\"âœ… All systems nominal! Mission tools loaded successfully!\")\n",
    "print(\"ğŸš€ Ready to launch our Spaceship Titanic investigation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ›ï¸ Mission Configuration: Setting Our Course\n",
    "\n",
    "Every good space mission needs a flight plan! Let's configure our settings to ensure our journey is smooth and reproducible.\n",
    "\n",
    "### ğŸ”§ Key Configuration Settings:\n",
    "- **RANDOM_STATE = 42**: The \"answer to everything\" - ensures we get the same results every time\n",
    "- **Train/Val/Test Split**: We'll use 60%/20%/20% split to properly evaluate our model\n",
    "- **MLflow Tracking**: Like a mission logbook - tracks every experiment we run\n",
    "\n",
    "> ğŸ¯ **Why This Matters**: Without proper configuration, your results might change every time you run the code - and you won't know why!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissionConfig:\n",
    "    \"\"\"Mission Configuration - Our Flight Plan for Success!\"\"\"\n",
    "    \n",
    "    # ğŸ¯ Reproducibility Settings (The \"Secret Sauce\")\n",
    "    RANDOM_STATE = 42  # The answer to life, universe, and reproducible ML!\n",
    "    TEST_SIZE = 0.2    # 20% for final testing - our \"final exam\"\n",
    "    VAL_SIZE = 0.25    # 25% of training data for validation (20% of total)\n",
    "    CV_FOLDS = 5       # 5-fold cross-validation for robust evaluation\n",
    "    N_JOBS = -1        # Use all CPU cores for faster training\n",
    "    \n",
    "    # ğŸ“ Mission Directories (Organizing Our Work)\n",
    "    MODEL_DIR = \"spaceship_models\"\n",
    "    EXPERIMENT_DIR = \"spaceship_experiments\" \n",
    "    SUBMISSION_DIR = \"kaggle_submissions\"\n",
    "    \n",
    "    # ğŸ› ï¸ Create mission directories\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(EXPERIMENT_DIR, exist_ok=True)\n",
    "    os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "    \n",
    "# Initialize our mission configuration\n",
    "config = MissionConfig()\n",
    "\n",
    "# ğŸ“Š Set up MLflow - Our Mission Logbook\n",
    "mlflow.set_tracking_uri(f\"file://{os.path.abspath(config.EXPERIMENT_DIR)}\")\n",
    "experiment_name = \"spaceship_titanic_mission\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(\"ğŸ›ï¸ MISSION CONFIGURATION COMPLETE!\")\n",
    "print(\"ğŸ“‹ Flight Plan Summary:\")\n",
    "print(f\"   â€¢ Random Seed: {config.RANDOM_STATE} (for reproducible results)\")\n",
    "print(f\"   â€¢ Data Split: 60% Train / 20% Validation / 20% Test\")\n",
    "print(f\"   â€¢ Cross-Validation: {config.CV_FOLDS}-fold (robust evaluation)\")\n",
    "print(f\"   â€¢ Model Directory: {config.MODEL_DIR}\")\n",
    "print(f\"   â€¢ Experiment Tracking: {config.EXPERIMENT_DIR}\")\n",
    "print(\"\\nğŸš€ All systems go! Ready to load passenger data!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“¥ Loading Passenger Data: The Investigation Begins!\n",
    "\n",
    "## ğŸ•µï¸â€â™‚ï¸ Our Mission: Investigate the Passenger Manifest\n",
    "\n",
    "We have two key files:\n",
    "- `train.csv`: Contains passenger information AND whether they were transported (our training data)\n",
    "- `test.csv`: Contains passenger information ONLY - we need to predict who was transported\n",
    "\n",
    "### ğŸ” What We're Looking For:\n",
    "- **Patterns**: What characteristics made someone more likely to be transported?\n",
    "- **Clues**: Missing data, unusual distributions, interesting correlations\n",
    "- **Insights**: Stories hidden in the data that our model can learn from\n",
    "\n",
    "> ğŸ¯ **Detective Mindset**: Approach this like a mystery novel - every column could hold a clue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‚ Loading our passenger manifests\n",
    "print(\"ğŸ•µï¸ Loading Spaceship Titanic Passenger Data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Try to load from local files first\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    print(\"âœ… Passenger manifests loaded from local files!\")\n",
    "except FileNotFoundError:\n",
    "    # If files aren't found, download from Kaggle\n",
    "    print(\"ğŸ“¥ Downloading passenger data from Kaggle...\")\n",
    "    try:\n",
    "        import kaggle\n",
    "        kaggle.api.competition_download_files('spaceship-titanic', path='.')\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile('spaceship-titanic.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        train_df = pd.read_csv('train.csv')\n",
    "        test_df = pd.read_csv('test.csv')\n",
    "        print(\"âœ… Data downloaded and extracted successfully!\")\n",
    "    except:\n",
    "        print(\"âŒ Could not download data. Please ensure you have the datasets in your directory.\")\n",
    "        raise\n",
    "\n",
    "# ğŸ¯ Initial Data Reconnaissance\n",
    "print(f\"\\nğŸ“Š TRAINING DATA: {train_df.shape[0]} passengers, {train_df.shape[1]} features\")\n",
    "print(f\"ğŸ“ˆ TEST DATA: {test_df.shape[0]} passengers, {test_df.shape[1]} features\")\n",
    "\n",
    "print(\"\\nğŸ” First Look at Our Passengers:\")\n",
    "print(\"-\" * 50)\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nğŸ“‹ Passenger Manifest Overview:\")\n",
    "print(\"-\" * 50)\n",
    "train_df.info()\n",
    "\n",
    "# ğŸ¯ Quick Facts About Our Mission\n",
    "print(f\"\\nğŸš€ MISSION BRIEFING:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"â€¢ Total Passengers to Investigate: {len(train_df) + len(test_df):,}\")\n",
    "print(f\"â€¢ Training Samples (Known Outcomes): {len(train_df):,}\")\n",
    "print(f\"â€¢ Test Samples (Mystery Cases): {len(test_df):,}\")\n",
    "print(f\"â€¢ Features Available: {train_df.shape[1] - 1}\")  # -1 for target\n",
    "print(f\"â€¢ Target Variable: 'Transported' (True/False)\")\n",
    "\n",
    "# Store test passenger IDs for our final submission\n",
    "test_passenger_ids = test_df['PassengerId'].copy()\n",
    "print(f\"\\nğŸ“ Saved {len(test_passenger_ids)} passenger IDs for Kaggle submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§¹ Data Cleaning: Preparing Our Evidence\n",
    "\n",
    "## ğŸ§¼ Why Clean Data Matters:\n",
    "\n",
    "Real-world data is like a crime scene - it's often messy! We need to:\n",
    "- **Handle missing values** (like incomplete witness statements)\n",
    "- **Fix data types** (making sure numbers are numbers, categories are categories)\n",
    "- **Prepare for analysis** (so our models can understand the data)\n",
    "\n",
    "### ğŸ¯ Our Cleaning Strategy:\n",
    "1. **Separate features from target** (what we're trying to predict)\n",
    "2. **Analyze missing data** - where are the gaps in our evidence?\n",
    "3. **Understand our baseline** - what if we just guessed?\n",
    "\n",
    "> ğŸ” **Investigator's Note**: Pay attention to missing values - sometimes the pattern of what's missing can be a clue itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¹ STEP 1: Create clean copies of our data\n",
    "print(\"ğŸ§¹ Beginning Data Cleaning Procedure...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_clean = train_df.copy()\n",
    "test_clean = test_df.copy()\n",
    "\n",
    "# ğŸ¯ Separate our evidence (features) from what we're trying to predict (target)\n",
    "X = train_clean.drop('Transported', axis=1)  # Features - what we know\n",
    "y = train_clean['Transported'].astype(int)   # Target - what we want to predict (convert True/False to 1/0)\n",
    "\n",
    "print(\"âœ… Separated features from target variable\")\n",
    "print(f\"   â€¢ Features (X): {X.shape[1]} columns\")\n",
    "print(f\"   â€¢ Target (y): 1 column ('Transported')\")\n",
    "\n",
    "# ğŸ” Investigate Missing Evidence\n",
    "print(\"\\nğŸ” ANALYZING MISSING DATA:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "missing_data = X.isnull().sum()\n",
    "missing_percent = (missing_data / len(X)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "# Only show columns with missing data\n",
    "missing_columns = missing_df[missing_df['Missing Count'] > 0]\n",
    "print(f\"ğŸ“Š Found {len(missing_columns)} features with missing data:\")\n",
    "display(missing_columns)\n",
    "\n",
    "# ğŸ¯ Understanding Our Baseline\n",
    "print(\"\\nğŸ¯ BASELINE ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "transported_stats = y.value_counts()\n",
    "baseline_accuracy = max(transported_stats) / len(y)\n",
    "\n",
    "print(f\"ğŸ“Š Target Distribution:\")\n",
    "print(f\"   â€¢ Transported (1): {transported_stats[1]:,} passengers ({transported_stats[1]/len(y)*100:.1f}%)\")\n",
    "print(f\"   â€¢ Not Transported (0): {transported_stats[0]:,} passengers ({transported_stats[0]/len(y)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ BASELINE STRATEGY:\")\n",
    "print(f\"   If we predicted '{'TRANSPORTED' if transported_stats[1] > transported_stats[0] else 'NOT TRANSPORTED'}' for everyone...\")\n",
    "print(f\"   We would be correct {baseline_accuracy:.1%} of the time\")\n",
    "\n",
    "print(f\"\\nğŸ¯ OUR MISSION: Beat the baseline of {baseline_accuracy:.1%} accuracy!\")\n",
    "\n",
    "# ğŸ“ˆ Visualize the target distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=y, palette=['#ff6b6b', '#51cf66'])\n",
    "plt.title('Passenger Transport Status\\n(0 = Not Transported, 1 = Transported)')\n",
    "plt.xlabel('Transported')\n",
    "plt.ylabel('Number of Passengers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(transported_stats.values, labels=['Not Transported', 'Transported'], \n",
    "        autopct='%1.1f%%', colors=['#ff6b6b', '#51cf66'], startangle=90)\n",
    "plt.title('Transportation Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Data cleaning phase complete! Ready for deep investigation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” Deep Data Investigation: Finding Clues\n",
    "\n",
    "## ğŸ•µï¸â€â™‚ï¸ Time to Play Detective!\n",
    "\n",
    "Now we'll explore our data to find patterns and clues. We're looking for:\n",
    "- **Numerical patterns**: Age, spending habits\n",
    "- **Categorical clues**: Home planet, cryosleep status, destination\n",
    "- **Interesting relationships**: How different factors interact\n",
    "\n",
    "### ğŸ¯ Investigation Strategy:\n",
    "1. **Numerical Features**: Distributions and outliers\n",
    "2. **Categorical Features**: Proportions and relationships\n",
    "3. **Spending Patterns**: Who spent money where?\n",
    "\n",
    "> ğŸ”¬ **Forensic Mindset**: Look for unusual patterns - they often reveal the most interesting stories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¨ Set up our investigation visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"ğŸ” Beginning Deep Data Investigation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. ğŸ¯ NUMERICAL FEATURES INVESTIGATION\n",
    "print(\"\\n1ï¸âƒ£ NUMERICAL FEATURES: Age and Spending Habits\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "numerical_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "print(\"ğŸ“Š Numerical Features Summary:\")\n",
    "numerical_summary = train_df[numerical_features].describe()\n",
    "display(numerical_summary)\n",
    "\n",
    "# Create comprehensive numerical visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    # Create distribution plot\n",
    "    sns.histplot(data=train_df, x=feature, hue='Transported', ax=axes[i], bins=30, alpha=0.7)\n",
    "    axes[i].set_title(f'{feature} Distribution\\n(Colored by Transport Status)')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    \n",
    "    # Add some statistics\n",
    "    transported_mean = train_df[train_df['Transported'] == True][feature].mean()\n",
    "    not_transported_mean = train_df[train_df['Transported'] == False][feature].mean()\n",
    "    \n",
    "    axes[i].axvline(transported_mean, color='blue', linestyle='--', alpha=0.7, label=f'Transported Mean: {transported_mean:.1f}')\n",
    "    axes[i].axvline(not_transported_mean, color='red', linestyle='--', alpha=0.7, label=f'Not Transported Mean: {not_transported_mean:.1f}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. ğŸ¯ CATEGORICAL FEATURES INVESTIGATION  \n",
    "print(\"\\n2ï¸âƒ£ CATEGORICAL FEATURES: Background and Choices\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "categorical_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    # Calculate transportation rates by category\n",
    "    category_stats = train_df.groupby(feature)['Transported'].agg(['mean', 'count']).reset_index()\n",
    "    category_stats['transport_rate'] = category_stats['mean'] * 100\n",
    "    \n",
    "    # Create bar plot\n",
    "    sns.barplot(data=category_stats, x=feature, y='transport_rate', ax=axes[i], palette='viridis')\n",
    "    axes[i].set_title(f'{feature} vs Transport Rate\\n(Higher = More Likely Transported)')\n",
    "    axes[i].set_ylabel('Transport Rate (%)')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    \n",
    "    # Add value labels\n",
    "    for j, (_, row) in enumerate(category_stats.iterrows()):\n",
    "        axes[i].text(j, row['transport_rate'] + 1, f\"{row['transport_rate']:.1f}%\", \n",
    "                   ha='center', va='bottom', fontweight='bold')\n",
    "        axes[i].text(j, -5, f\"n={row['count']}\", ha='center', va='top', fontsize=9, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ğŸ” KEY INSIGHTS AND PATTERNS\n",
    "print(\"\\n3ï¸âƒ£ KEY INVESTIGATION FINDINGS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate some interesting insights\n",
    "cryosleep_effect = train_df.groupby('CryoSleep')['Transported'].mean()\n",
    "homeplanet_effect = train_df.groupby('HomePlanet')['Transported'].mean()\n",
    "\n",
    "print(\"ğŸ”¬ INTERESTING PATTERNS FOUND:\")\n",
    "print(f\"   â€¢ CryoSleep Effect: {cryosleep_effect[True]:.1%} of cryosleep passengers transported vs {cryosleep_effect[False]:.1%} of awake passengers\")\n",
    "print(f\"   â€¢ Home Planet Variations: {homeplanet_effect.idxmax()} has highest transport rate ({homeplanet_effect.max():.1%})\")\n",
    "print(f\"   â€¢ Age Pattern: Younger passengers seem slightly more likely to be transported\")\n",
    "print(f\"   â€¢ Spending: Passengers with zero spending more likely to be transported\")\n",
    "\n",
    "print(\"\\nğŸ¯ INVESTIGATION COMPLETE! Found several promising clues for our model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¨ Advanced Feature Engineering: Creating Super Clues!\n",
    "\n",
    "## ğŸ§  Why Feature Engineering Matters:\n",
    "\n",
    "Sometimes the raw data doesn't tell the whole story. We can create **new features** (\"super clues\") that combine information in clever ways!\n",
    "\n",
    "### ğŸ¯ Our Feature Engineering Strategy:\n",
    "1. **Extract group information** from PassengerId\n",
    "2. **Decompose Cabin** into deck, number, and side\n",
    "3. **Create spending features** - total spending and spending indicators\n",
    "4. **Add demographic features** - age groups, family size\n",
    "\n",
    "> ğŸ’¡ **Creative Insight**: The best features often come from domain knowledge and creative thinking about what might matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceshipDetective:\n",
    "    \"\"\"\n",
    "    ğŸ•µï¸ Advanced Feature Engineer for Spaceship Titanic\n",
    "    \n",
    "    This class creates powerful new features by combining existing information\n",
    "    in clever ways to help our model find hidden patterns!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_names = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting needed for this transformer - it's all based on the data\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_eng = X.copy()\n",
    "        \n",
    "        print(\"ğŸ› ï¸ Creating advanced features...\")\n",
    "        \n",
    "        # ğŸ” CLUE 1: Extract Group Information from PassengerId\n",
    "        # Format: XXXX_XX where first part is group ID, second is passenger in group\n",
    "        X_eng['GroupId'] = X_eng['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "        X_eng['GroupSize'] = X_eng.groupby('GroupId')['GroupId'].transform('count')\n",
    "        \n",
    "        # ğŸ” CLUE 2: Decompose Cabin into useful parts\n",
    "        # Format: Deck/Number/Side (e.g., B/123/P)\n",
    "        cabin_decomposed = X_eng['Cabin'].str.split('/', expand=True)\n",
    "        X_eng['CabinDeck'] = cabin_decomposed[0]  # Deck level\n",
    "        X_eng['CabinNum'] = pd.to_numeric(cabin_decomposed[1], errors='coerce')  # Cabin number\n",
    "        X_eng['CabinSide'] = cabin_decomposed[2]  # Port (P) or Starboard (S)\n",
    "        \n",
    "        # ğŸ” CLUE 3: Create Spending Features\n",
    "        spending_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "        X_eng['TotalSpending'] = X_eng[spending_features].sum(axis=1)\n",
    "        X_eng['HasSpending'] = (X_eng['TotalSpending'] > 0).astype(int)\n",
    "        \n",
    "        # ğŸ” CLUE 4: Create Demographic Features\n",
    "        # Age groups that might behave differently\n",
    "        X_eng['AgeGroup'] = pd.cut(X_eng['Age'], \n",
    "                                  bins=[0, 12, 18, 30, 50, 100], \n",
    "                                  labels=['Child', 'Teen', 'Young Adult', 'Adult', 'Senior'])\n",
    "        \n",
    "        # Family/Social features\n",
    "        X_eng['IsAlone'] = (X_eng['GroupSize'] == 1).astype(int)\n",
    "        X_eng['IsChild'] = (X_eng['Age'] < 13).astype(int)\n",
    "        X_eng['IsElderly'] = (X_eng['Age'] > 60).astype(int)\n",
    "        \n",
    "        # ğŸ” CLUE 5: Create Interaction Features\n",
    "        # Wealth indicator: VIP status combined with spending\n",
    "        X_eng['WealthIndicator'] = X_eng['VIP'].astype(int) * X_eng['TotalSpending']\n",
    "        \n",
    "        # ğŸ” CLUE 6: Spending Ratios\n",
    "        # What percentage of total spending goes to luxury vs necessities?\n",
    "        X_eng['LuxuryRatio'] = (X_eng['RoomService'] + X_eng['Spa'] + X_eng['VRDeck']) / (X_eng['TotalSpending'] + 1)\n",
    "        X_eng['FoodRatio'] = X_eng['FoodCourt'] / (X_eng['TotalSpending'] + 1)\n",
    "        \n",
    "        # ğŸ§¹ Clean up: Remove original columns we've decomposed\n",
    "        columns_to_drop = ['PassengerId', 'Cabin', 'Name']\n",
    "        X_eng = X_eng.drop([col for col in columns_to_drop if col in X_eng.columns], axis=1)\n",
    "        \n",
    "        # ğŸ“ Track our new feature names\n",
    "        self.feature_names = list(X_eng.columns)\n",
    "        \n",
    "        return X_eng\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "# ğŸš€ Let's test our feature engineering!\n",
    "print(\"ğŸ¨ Starting Advanced Feature Engineering...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "detective = SpaceshipDetective()\n",
    "X_engineered = detective.fit_transform(X)\n",
    "\n",
    "print(f\"\\nâœ… FEATURE ENGINEERING COMPLETE!\")\n",
    "print(f\"ğŸ“Š Original features: {X.shape[1]}\")\n",
    "print(f\"ğŸš€ Engineered features: {X_engineered.shape[1]}\")\n",
    "print(f\"ğŸ¯ New features created: {X_engineered.shape[1] - X.shape[1]}\")\n",
    "\n",
    "# Show our new features\n",
    "new_features = [f for f in X_engineered.columns if f not in X.columns]\n",
    "print(f\"\\nğŸ” NEW FEATURES CREATED:\")\n",
    "for i, feature in enumerate(new_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Preview of Engineered Data:\")\n",
    "print(\"-\" * 50)\n",
    "display(X_engineered.head())\n",
    "\n",
    "print(\"\\nğŸ‰ Feature engineering successful! Our model now has powerful new clues to work with!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ—ï¸ Building Our Preprocessing Pipeline\n",
    "\n",
    "## ğŸ› ï¸ Why Pipelines Matter:\n",
    "\n",
    "A pipeline is like an assembly line for your data - it automatically handles:\n",
    "- **Missing values** (filling in gaps)\n",
    "- **Scaling** (making sure all features play fair)\n",
    "- **Encoding** (converting categories to numbers)\n",
    "\n",
    "### ğŸ¯ Pipeline Benefits:\n",
    "- **Reproducible**: Same steps every time\n",
    "- **Prevents Data Leakage**: No information from test set leaks into training\n",
    "- **Easy Deployment**: One object handles all preprocessing\n",
    "\n",
    "> ğŸ’¡ **Pro Tip**: Pipelines are essential for professional ML workflows - they prevent common mistakes and save time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ—ï¸ Building Advanced Preprocessing Pipeline...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ğŸ” Identify different types of features\n",
    "numerical_features = X_engineered.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_engineered.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"ğŸ“Š FEATURE ANALYSIS:\")\n",
    "print(f\"   â€¢ Numerical Features: {len(numerical_features)}\")\n",
    "print(f\"   â€¢ Categorical Features: {len(categorical_features)}\")\n",
    "print(f\"   â€¢ Total Features: {len(numerical_features) + len(categorical_features)}\")\n",
    "\n",
    "# ğŸ› ï¸ Build Numerical Pipeline\n",
    "print(\"\\nğŸ› ï¸ Building Numerical Pipeline...\")\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Fill missing values with median\n",
    "    ('scaler', RobustScaler())  # Scale features, robust to outliers\n",
    "])\n",
    "\n",
    "# ğŸ› ï¸ Build Categorical Pipeline  \n",
    "print(\"ğŸ› ï¸ Building Categorical Pipeline...\")\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing with most common category\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Convert categories to numbers\n",
    "])\n",
    "\n",
    "# ğŸ¯ Create Column Transformer (applies different pipelines to different columns)\n",
    "print(\"ğŸ¯ Creating Column Transformer...\")\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# ğŸš€ Create Full Pipeline (Feature Engineering + Preprocessing)\n",
    "print(\"ğŸš€ Creating Full Pipeline...\")\n",
    "full_pipeline = Pipeline([\n",
    "    ('feature_engineer', SpaceshipDetective()),\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# ğŸ”§ Apply our pipeline to the data\n",
    "print(\"\\nğŸ”§ Applying pipeline to training data...\")\n",
    "X_processed = full_pipeline.fit_transform(X, y)\n",
    "\n",
    "print(f\"\\nâœ… PIPELINE CONSTRUCTION COMPLETE!\")\n",
    "print(f\"ğŸ“Š Final processed data shape: {X_processed.shape}\")\n",
    "print(f\"ğŸ¯ Pipeline steps:\")\n",
    "for i, (name, step) in enumerate(full_pipeline.steps):\n",
    "    print(f\"   {i+1}. {name}: {step.__class__.__name__}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Pipeline is ready! It will automatically handle all preprocessing for new data too!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§ª Train-Validation-Test Split: Setting Up Our Experiments\n",
    "\n",
    "## ğŸ¯ Why We Split Data:\n",
    "\n",
    "We need to test our model on data it hasn't seen before to make sure it actually works! Think of it like:\n",
    "- **Training Set**: Textbook (what the model studies)\n",
    "- **Validation Set**: Practice exams (how we tune the model)\n",
    "- **Test Set**: Final exam (true measure of performance)\n",
    "\n",
    "### ğŸ“Š Our Split Strategy:\n",
    "- **60% Training**: For the model to learn patterns\n",
    "- **20% Validation**: For tuning hyperparameters\n",
    "- **20% Test**: For final evaluation (never touch until the end!)\n",
    "\n",
    "> ğŸš« **Critical Rule**: Never let the model see the test set during training - that's cheating!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª Setting Up Data Splits for Robust Evaluation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First split: Separate test set (our \"final exam\")\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_processed, y, \n",
    "    test_size=config.TEST_SIZE, \n",
    "    random_state=config.RANDOM_STATE, \n",
    "    stratify=y  # Keep same proportion of transported/not transported in each split\n",
    ")\n",
    "\n",
    "# Second split: Separate validation set (our \"practice exams\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=config.VAL_SIZE, \n",
    "    random_state=config.RANDOM_STATE, \n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"âœ… DATA SPLITS CREATED SUCCESSFULLY!\")\n",
    "print(\"\\nğŸ“Š SPLIT SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ğŸ« TRAINING SET: {X_train.shape[0]:,} passengers\")\n",
    "print(f\"   â€¢ Used for: Teaching the model patterns\")\n",
    "print(f\"   â€¢ Transported: {y_train.sum():,} ({y_train.mean():.1%})\")\n",
    "\n",
    "print(f\"\\nğŸ“ VALIDATION SET: {X_val.shape[0]:,} passengers\")  \n",
    "print(f\"   â€¢ Used for: Tuning model parameters\")\n",
    "print(f\"   â€¢ Transported: {y_val.sum():,} ({y_val.mean():.1%})\")\n",
    "\n",
    "print(f\"\\nğŸ¯ TEST SET: {X_test.shape[0]:,} passengers\")\n",
    "print(f\"   â€¢ Used for: Final evaluation (KEPT SECRET!)\")\n",
    "print(f\"   â€¢ Transported: {y_test.sum():,} ({y_test.mean():.1%})\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ TOTAL DATA: {X_processed.shape[0]:,} passengers\")\n",
    "print(f\"   â€¢ Features: {X_processed.shape[1]}\")\n",
    "print(f\"   â€¢ Transported Overall: {y.sum():,} ({y.mean():.1%})\")\n",
    "\n",
    "# Visualize our splits\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "split_data = [\n",
    "    ('Training', len(X_train), '#51cf66'),\n",
    "    ('Validation', len(X_val), '#ffd43b'), \n",
    "    ('Test', len(X_test), '#ff6b6b')\n",
    "]\n",
    "\n",
    "names, sizes, colors = zip(*split_data)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(sizes, labels=names, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Data Split Proportions')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bars = plt.bar(names, sizes, color=colors)\n",
    "plt.title('Data Split Sizes')\n",
    "plt.ylabel('Number of Passengers')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, size in zip(bars, sizes):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "             f'{size:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸš€ Data splits ready! Time to train some models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– Assembling Our Model Team\n",
    "\n",
    "## ğŸ¯ Why Multiple Models Matter:\n",
    "\n",
    "Different models have different strengths - like having a team of specialists!\n",
    "\n",
    "| Model | Speciality | Best For |\n",
    "|-------|------------|----------|\n",
    "| **Logistic Regression** | Simple, interpretable | Linear relationships, baseline |\n",
    "| **Random Forest** | Robust, handles mixed data | Complex patterns, feature importance |\n",
    "| **Gradient Boosting** | High accuracy, sequential learning | Winning competitions! |\n",
    "| **SVM** | Complex boundaries | High-dimensional spaces |\n",
    "| **K-Neighbors** | Instance-based | Local patterns, similar passengers |\n",
    "| **Voting Ensemble** | Wisdom of crowds | Combining strengths of multiple models |\n",
    "\n",
    "> ğŸ¯ **Strategy**: We'll try them all and see which one performs best on our validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– Assembling Our Machine Learning Team...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define our model team\n",
    "model_team = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=config.RANDOM_STATE, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=config.RANDOM_STATE, n_jobs=config.N_JOBS),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=config.RANDOM_STATE),\n",
    "    'Support Vector Machine': SVC(random_state=config.RANDOM_STATE, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_jobs=config.N_JOBS),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=config.RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# Create a super-team: Voting Ensemble\n",
    "print(\"ğŸŒŸ Creating Super Team: Voting Ensemble...\")\n",
    "voting_ensemble = VotingClassifier([\n",
    "    ('rf', RandomForestClassifier(random_state=config.RANDOM_STATE, n_jobs=config.N_JOBS)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=config.RANDOM_STATE)),\n",
    "    ('lr', LogisticRegression(random_state=config.RANDOM_STATE, max_iter=1000))\n",
    "], voting='soft')  # 'soft' = use probabilities instead of hard votes\n",
    "\n",
    "model_team['Voting Ensemble'] = voting_ensemble\n",
    "\n",
    "print(\"âœ… MODEL TEAM ASSEMBLED!\")\n",
    "print(f\"\\nğŸ‘¥ TEAM MEMBERS: {len(model_team)} models\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, (name, model) in enumerate(model_team.items(), 1):\n",
    "    print(f\"{i:2d}. {name:25} - {model.__class__.__name__}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ STRATEGY: Train all models, then select the best performer!\")\n",
    "print(\"ğŸ’¡ We'll use MLflow to track every experiment automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Model Training & Evaluation: The Grand Tournament!\n",
    "\n",
    "## ğŸ† How We'll Judge Our Models:\n",
    "\n",
    "We'll use multiple metrics to get a complete picture:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: When we say \"transported\", how often are we right?\n",
    "- **Recall**: How many actual transported passengers do we catch?\n",
    "- **F1-Score**: Balance between precision and recall\n",
    "- **ROC-AUC**: Overall model performance across all thresholds\n",
    "\n",
    "> ğŸ“Š **MLflow Magic**: Every model, every parameter, every result will be automatically tracked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_tournament(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    \"\"\"\n",
    "    ğŸ† Run a complete model evaluation with comprehensive tracking\n",
    "    \n",
   "    This function trains a model, evaluates it on multiple metrics,\n",
    "    and logs everything to MLflow for comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # â±ï¸ Track training time\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # ğŸ”® Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # ğŸ“Š Calculate comprehensive metrics\n",
    "        metrics = {\n",
    "            'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'val_accuracy': accuracy_score(y_val, y_val_pred),\n",
    "            'train_precision': precision_score(y_train, y_train_pred),\n",
    "            'val_precision': precision_score(y_val, y_val_pred),\n",
    "            'train_recall': recall_score(y_train, y_train_pred),\n",
    "            'val_recall': recall_score(y_val, y_val_pred),\n",
    "            'train_f1': f1_score(y_train, y_train_pred),\n",
    "            'val_f1': f1_score(y_val, y_val_pred),\n",
    "            'training_time': training_time,\n",
    "            'overfitting_gap': accuracy_score(y_train, y_train_pred) - accuracy_score(y_val, y_val_pred)\n",
    "        }\n",
    "        \n",
    "        # Add ROC-AUC if we have probabilities\n",
    "        if y_val_proba is not None:\n",
    "            metrics['val_roc_auc'] = roc_auc_score(y_val, y_val_proba)\n",
    "        \n",
    "        # ğŸ“ Log to MLflow (our experiment tracker)\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metrics({k: v for k, v in metrics.items() if k != 'training_time'})\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # ğŸ”„ Cross-validation for robust performance estimate\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, \n",
    "                                  cv=config.CV_FOLDS, scoring='accuracy', \n",
    "                                  n_jobs=config.N_JOBS)\n",
    "        metrics['cv_accuracy_mean'] = cv_scores.mean()\n",
    "        metrics['cv_accuracy_std'] = cv_scores.std()\n",
    "        \n",
    "        mlflow.log_metrics({\n",
    "            'cv_accuracy_mean': metrics['cv_accuracy_mean'],\n",
    "            'cv_accuracy_std': metrics['cv_accuracy_std']\n",
    "        })\n",
    "        \n",
    "        return metrics, model\n",
    "\n",
    "# ğŸš€ Start the model tournament!\n",
    "print(\"ğŸš€ STARTING MODEL TOURNAMENT!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ† Each model will be trained and evaluated...\")\n",
    "print(\"ğŸ“Š MLflow is tracking all experiments automatically\\n\")\n",
    "\n",
    "tournament_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in model_team.items():\n",
    "    print(f\"ğŸ”§ Training {name}...\")\n",
    "    metrics, trained_model = run_model_tournament(\n",
    "        model, X_train, X_val, y_train, y_val, name\n",
    "    )\n",
    "    tournament_results[name] = metrics\n",
    "    trained_models[name] = trained_model\n",
    "    \n",
    "    # Show quick results\n",
    "    overfitting_indicator = \"âš ï¸\" if metrics['overfitting_gap'] > 0.1 else \"âœ…\"\n",
    "    print(f\"   âœ… {name:25} | Val Acc: {metrics['val_accuracy']:.4f} | \"\n",
    "          f\"CV Acc: {metrics['cv_accuracy_mean']:.4f} Â± {metrics['cv_accuracy_std']:.4f} \"\n",
    "          f\"{overfitting_indicator}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ TOURNAMENT COMPLETE!\")\n",
    "print(f\"ğŸ’¡ View detailed results: mlflow ui --backend-store-uri {config.EXPERIMENT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Tournament Results: And the Winner Is...\n",
    "\n",
    "## ğŸ† Time to Crown Our Champion!\n",
    "\n",
    "Let's analyze all the models and select the best one based on:\n",
    "- **Validation Accuracy**: Performance on unseen data\n",
    "- **Cross-Validation**: Robustness across different data splits\n",
    "- **Overfitting**: Gap between training and validation performance\n",
    "- **Training Time**: Computational efficiency\n",
    "\n",
    "> ğŸ¯ **Goal**: Find the model that generalizes best to new, unseen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Analyze tournament results\n",
    "print(\"ğŸ“Š ANALYZING TOURNAMENT RESULTS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_df = pd.DataFrame(tournament_results).T\n",
    "results_df = results_df.sort_values('val_accuracy', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ† FINAL TOURNAMENT STANDINGS:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Model':<22} {'Val Acc':<8} {'CV Acc':<12} {'Overfit':<10} {'Time (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank, (model_name, row) in enumerate(results_df.iterrows(), 1):\n",
    "    overfitting_indicator = \"âš ï¸ HIGH\" if row['overfitting_gap'] > 0.1 else \"âœ… LOW\"\n",
    "    medal = \"ğŸ¥‡\" if rank == 1 else \"ğŸ¥ˆ\" if rank == 2 else \"ğŸ¥‰\" if rank == 3 else \"  \"\n",
    "    \n",
    "    print(f\"{medal} {rank:<2} {model_name:<22} {row['val_accuracy']:>7.4f} \"\n",
    "          f\"{row['cv_accuracy_mean']:>7.4f} Â± {row['cv_accuracy_std']:>5.4f} \"\n",
    "          f\"{overfitting_indicator:<10} {row['training_time']:>9.2f}\")\n",
    "\n",
    "# ğŸ¯ Select the champion\n",
    "champion_name = results_df.index[0]\n",
    "champion_model = trained_models[champion_name]\n",
    "\n",
    "print(f\"\\nğŸ‰ TOURNAMENT CHAMPION: {champion_name}!\")\n",
    "print(f\"ğŸ“Š Validation Accuracy: {results_df.iloc[0]['val_accuracy']:.4f}\")\n",
    "print(f\"ğŸ” CV Accuracy: {results_df.iloc[0]['cv_accuracy_mean']:.4f} Â± {results_df.iloc[0]['cv_accuracy_std']:.4f}\")\n",
    "\n",
    "# ğŸ“Š Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Accuracy Comparison\n",
    "models_ordered = results_df.index\n",
    "val_acc = [tournament_results[model]['val_accuracy'] for model in models_ordered]\n",
    "train_acc = [tournament_results[model]['train_accuracy'] for model in models_ordered]\n",
    "\n",
    "x = np.arange(len(models_ordered))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[0, 0].bar(x - width/2, train_acc, width, label='Train Accuracy', alpha=0.7, color='skyblue')\n",
    "bars2 = axes[0, 0].bar(x + width/2, val_acc, width, label='Val Accuracy', alpha=0.7, color='lightcoral')\n",
    "axes[0, 0].set_xlabel('Models')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_title('Training vs Validation Accuracy\\n(Small gap = good generalization)')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(models_ordered, rotation=45, ha='right')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. F1-Score Comparison\n",
    "val_f1 = [tournament_results[model]['val_f1'] for model in models_ordered]\n",
    "bars = axes[0, 1].bar(models_ordered, val_f1, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_xlabel('Models')\n",
    "axes[0, 1].set_ylabel('F1-Score')\n",
    "axes[0, 1].set_title('Validation F1-Score\\n(Balances precision and recall)')\n",
    "axes[0, 1].set_xticklabels(models_ordered, rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, val_f1):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                   f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Training Time Comparison\n",
    "training_times = [tournament_results[model]['training_time'] for model in models_ordered]\n",
    "bars = axes[1, 0].bar(models_ordered, training_times, alpha=0.7, color='orange')\n",
    "axes[1, 0].set_xlabel('Models')\n",
    "axes[1, 0].set_ylabel('Training Time (seconds)')\n",
    "axes[1, 0].set_title('Computational Efficiency\\n(Faster training = more experimentation)')\n",
    "axes[1, 0].set_xticklabels(models_ordered, rotation=45, ha='right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. ROC-AUC Comparison\n",
    "roc_auc_scores = []\n",
    "model_names_roc = []\n",
    "for model_name in models_ordered:\n",
    "    if 'val_roc_auc' in tournament_results[model_name]:\n",
    "        roc_auc_scores.append(tournament_results[model_name]['val_roc_auc'])\n",
    "        model_names_roc.append(model_name)\n",
    "\n",
    "if roc_auc_scores:\n",
    "    bars = axes[1, 1].bar(model_names_roc, roc_auc_scores, alpha=0.7, color='purple')\n",
    "    axes[1, 1].set_xlabel('Models')\n",
    "    axes[1, 1].set_ylabel('ROC-AUC Score')\n",
    "    axes[1, 1].set_title('ROC-AUC Comparison\\n(Higher = better overall performance)')\n",
    "    axes[1, 1].set_xticklabels(model_names_roc, rotation=45, ha='right')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, roc_auc_scores):\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                       f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ¯ ANALYSIS COMPLETE! We have our champion model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš™ï¸ Hyperparameter Tuning: Making Our Champion Even Stronger!\n",
    "\n",
    "## ğŸ¯ What is Hyperparameter Tuning?\n",
    "\n",
    "Think of hyperparameters as the \"knobs and dials\" on our model. Tuning them is like:\n",
    "- **Fine-tuning a radio** to get the clearest signal\n",
    "- **Adjusting a recipe** to make it taste perfect\n",
    "- **Optimizing a car** for peak performance\n",
    "\n",
    "### ğŸš€ Our Tuning Strategy:\n",
    "We'll use **RandomizedSearchCV** which tries random combinations of hyperparameters - it's faster than trying every single combination!\n",
    "\n",
    "> ğŸ’¡ **Pro Tip**: Tuning can often improve model performance by 2-5% - that's huge in competitions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Define hyperparameter search spaces for our top models\n",
    "hyperparameter_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300, 400],  # Number of trees\n",
    "        'max_depth': [None, 10, 20, 30],       # How deep each tree can grow\n",
    "        'min_samples_split': [2, 5, 10],       # Minimum samples to split a node\n",
    "        'min_samples_leaf': [1, 2, 4],         # Minimum samples at a leaf node\n",
    "        'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider for splits\n",
    "    },\n",
    "    \n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],        # Number of boosting stages\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],  # How much each tree contributes\n",
    "        'max_depth': [3, 4, 5, 6],             # Maximum depth of each tree\n",
    "        'min_samples_split': [2, 5, 10],       # Minimum samples to split\n",
    "        'subsample': [0.8, 0.9, 1.0]           # Fraction of samples used for fitting\n",
    "    },\n",
    "    \n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization strength\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],       # Type of regularization\n",
    "        'solver': ['liblinear', 'saga']              # Optimization algorithm\n",
    "    }\n",
    "}\n",
    "\n",
    "# ğŸš€ Start hyperparameter tuning for top models\n",
    "print(\"âš™ï¸ STARTING HYPERPARAMETER TUNING...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ Tuning top 3 models from our tournament...\\n\")\n",
    "\n",
    "tuned_champions = {}\n",
    "tuning_results = {}\n",
    "\n",
    "# Tune the top 3 models\n",
    "top_models_to_tune = results_df.index[:3]\n",
    "\n",
    "for model_name in top_models_to_tune:\n",
    "    if model_name in hyperparameter_grids:\n",
    "        print(f\"ğŸ”§ Tuning {model_name}...\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"{model_name}_TUNED\"):\n",
    "            # Use RandomizedSearchCV for efficient hyperparameter search\n",
    "            search = RandomizedSearchCV(\n",
    "                model_team[model_name],           # The model to tune\n",
    "                hyperparameter_grids[model_name], # Parameter grid to search\n",
    "                n_iter=20,                       # Try 20 random combinations\n",
    "                cv=config.CV_FOLDS,              # 5-fold cross-validation\n",
    "                scoring='accuracy',              # Optimize for accuracy\n",
    "                n_jobs=config.N_JOBS,            # Use all CPU cores\n",
    "                random_state=config.RANDOM_STATE,# For reproducibility\n",
    "                verbose=1                        # Show progress\n",
    "            )\n",
    "            \n",
    "            # ğŸ” Perform the search!\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # ğŸ’¾ Store the tuned champion\n",
    "            tuned_champions[model_name] = search.best_estimator_\n",
    "            tuning_results[model_name] = {\n",
    "                'best_score': search.best_score_,\n",
    "                'best_params': search.best_params_,\n",
    "                'best_estimator': search.best_estimator_\n",
    "            }\n",
    "            \n",
    "            # ğŸ“ Log everything to MLflow\n",
    "            mlflow.log_params(search.best_params_)\n",
    "            mlflow.log_metric('best_cv_score', search.best_score_)\n",
    "            mlflow.sklearn.log_model(search.best_estimator_, \"tuned_model\")\n",
    "            \n",
    "            print(f\"   âœ… {model_name:20} | Best CV Accuracy: {search.best_score_:.4f}\")\n",
    "            print(f\"      Improvement: +{search.best_score_ - tournament_results[model_name]['cv_accuracy_mean']:.4f}\")\n",
    "            print(f\"      Best parameters: {search.best_params_}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(\"ğŸ’¡ Our models are now optimized for peak performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ† Final Model Selection: Choosing Our Ultimate Champion\n",
    "\n",
    "## ğŸ¯ Time for the Final Decision!\n",
    "\n",
    "We'll evaluate our tuned models on the validation set and select the absolute best performer. Then we'll do a final evaluation on the **test set** (which we've kept completely separate until now!).\n",
    "\n",
    "### ğŸ”¬ Our Evaluation Criteria:\n",
    "- **Validation Accuracy**: Primary metric\n",
    "- **F1-Score**: Balance of precision and recall  \n",
    "- **ROC-AUC**: Overall model performance\n",
    "- **Stability**: Consistent performance across metrics\n",
    "\n",
    "> ğŸš¨ **Important**: This is our last chance to choose before the final test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ† Evaluate tuned champions on validation set\n",
    "print(\"ğŸ† FINAL MODEL SELECTION ROUND...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_results = {}\n",
    "for model_name, tuned_model in tuned_champions.items():\n",
    "    # Make predictions on validation set\n",
    "    y_val_pred = tuned_model.predict(X_val)\n",
    "    y_val_proba = tuned_model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    \n",
    "    # Compare with untuned version\n",
    "    improvement = val_accuracy - tournament_results[model_name]['val_accuracy']\n",
    "    \n",
    "    final_results[model_name] = {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_f1': val_f1,\n",
    "        'val_roc_auc': val_roc_auc,\n",
    "        'improvement': improvement\n",
    "    }\n",
    "\n",
    "# ğŸ¯ Print comparison between tuned and untuned\n",
    "print(\"\\nğŸ“Š TUNED vs UNTUNED PERFORMANCE:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Model':<20} {'Untuned Acc':<12} {'Tuned Acc':<12} {'Improvement':<12} {'F1-Score':<10} {'ROC-AUC':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_name, res in final_results.items():\n",
    "    untuned_acc = tournament_results[model_name]['val_accuracy']\n",
    "    tuned_acc = res['val_accuracy']\n",
    "    improvement = res['improvement']\n",
    "    \n",
    "    icon = \"ğŸ“ˆ\" if improvement > 0 else \"ğŸ“‰\" if improvement < 0 else \"â¡ï¸\"\n",
    "    \n",
    "    print(f\"{model_name:<20} {untuned_acc:>10.4f} {tuned_acc:>10.4f} {icon} {improvement:>8.4f} \"\n",
    "          f\"{res['val_f1']:>10.4f} {res['val_roc_auc']:>10.4f}\")\n",
    "\n",
    "# ğŸ… Select the ultimate champion\n",
    "ultimate_champion_name = max(final_results, key=lambda m: final_results[m]['val_accuracy'])\n",
    "ultimate_champion = tuned_champions[ultimate_champion_name]\n",
    "\n",
    "print(f\"\\nğŸ‰ ULTIMATE CHAMPION SELECTED: {ultimate_champion_name}!\")\n",
    "print(f\"ğŸ“Š Validation Accuracy: {final_results[ultimate_champion_name]['val_accuracy']:.4f}\")\n",
    "print(f\"ğŸ“ˆ Improvement from tuning: +{final_results[ultimate_champion_name]['improvement']:.4f}\")\n",
    "print(f\"ğŸ¯ F1-Score: {final_results[ultimate_champion_name]['val_f1']:.4f}\")\n",
    "print(f\"ğŸ“Š ROC-AUC: {final_results[ultimate_champion_name]['val_roc_auc']:.4f}\")\n",
    "\n",
    "# ğŸ§ª FINAL TEST SET EVALUATION (The moment of truth!)\n",
    "print(f\"\\nğŸ§ª FINAL TEST SET EVALUATION:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "y_test_pred = ultimate_champion.predict(X_test)\n",
    "y_test_proba = ultimate_champion.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"ğŸ“Š Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"ğŸ¯ Test Precision: {test_precision:.4f}\")\n",
    "print(f\"ğŸ” Test Recall: {test_recall:.4f}\")\n",
    "print(f\"âš–ï¸ Test F1-Score: {test_f1:.4f}\")\n",
    "print(f\"ğŸ“ˆ Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "baseline_accuracy = max(y_test.value_counts()) / len(y_test)\n",
    "improvement_over_baseline = test_accuracy - baseline_accuracy\n",
    "\n",
    "print(f\"\\nğŸ’¡ IMPROVEMENT OVER BASELINE: +{improvement_over_baseline:.4f} ({improvement_over_baseline/.01:.1f}% relative improvement!)\")\n",
    "\n",
    "# ğŸ“Š Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Transported', 'Transported'],\n",
    "            yticklabels=['Not Transported', 'Transported'])\n",
    "plt.title('Confusion Matrix - Test Set\\n(How our model performed)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "metrics_values = [test_accuracy, test_precision, test_recall, test_f1, test_roc_auc]\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "colors = ['#51cf66', '#ffd43b', '#ffa94d', '#ff6b6b', '#748ffc']\n",
    "\n",
    "bars = plt.bar(metrics_names, metrics_values, color=colors, alpha=0.7)\n",
    "plt.title('Test Set Performance Metrics')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ“‹ Detailed Classification Report\n",
    "print(\"\\nğŸ“‹ DETAILED CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['Not Transported', 'Transported']))\n",
    "\n",
    "print(\"\\nğŸ‰ FINAL EVALUATION COMPLETE! Our model is ready for Kaggle!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Preparing for Kaggle Submission\n",
    "\n",
    "## ğŸ“¤ Getting Ready for the Competition!\n",
    "\n",
    "Now we'll:\n",
    "1. **Retrain our champion** on all available training data\n",
    "2. **Generate predictions** for the test set\n",
    "3. **Create the submission file** in the proper format\n",
    "4. **Save all our work** for future use\n",
    "\n",
    "### ğŸ¯ Submission Format:\n",
    "We need a CSV with two columns:\n",
    "- `PassengerId`: The passenger identifier\n",
    "- `Transported`: `True` or `False` predictions\n",
    "\n",
    "> ğŸ’¡ **Pro Tip**: Always retrain your final model on all available data before submission - more data usually means better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Retrain champion on full training data\n",
    "print(\"ğŸš€ PREPARING KAGGLE SUBMISSION...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ”„ Retraining ultimate champion on full training data...\")\n",
    "X_full_train = np.vstack([X_train, X_val])\n",
    "y_full_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "final_champion = ultimate_champion\n",
    "final_champion.fit(X_full_train, y_full_train)\n",
    "\n",
    "print(\"âœ… Model retrained on full dataset\")\n",
    "print(f\"   â€¢ Training samples: {X_full_train.shape[0]:,}\")\n",
    "print(f\"   â€¢ Features: {X_full_train.shape[1]}\")\n",
    "\n",
    "# ğŸ”® Generate predictions for test set\n",
    "print(\"\\nğŸ”® Generating predictions for competition test set...\")\n",
    "test_processed = full_pipeline.transform(test_df)\n",
    "test_predictions = final_champion.predict(test_processed)\n",
    "test_probabilities = final_champion.predict_proba(test_processed)[:, 1]\n",
    "\n",
    "print(\"âœ… Predictions generated\")\n",
    "print(f\"   â€¢ Test passengers: {len(test_predictions):,}\")\n",
    "print(f\"   â€¢ Predicted transported: {test_predictions.sum():,} ({test_predictions.mean():.1%})\")\n",
    "\n",
    "# ğŸ“ Create submission DataFrame\n",
    "print(\"\\nğŸ“ Creating submission file...\")\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_passenger_ids,\n",
    "    'Transported': test_predictions.astype(bool)  # Convert back to True/False\n",
    "})\n",
    "\n",
    "# ğŸ’¾ Save submission file\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission_filename = f\"submission_{timestamp}.csv\"\n",
    "submission_path = os.path.join(config.SUBMISSION_DIR, submission_filename)\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"âœ… Submission file saved: {submission_path}\")\n",
    "\n",
    "# ğŸ“Š Analyze our submission\n",
    "print(\"\\nğŸ“Š SUBMISSION ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ğŸ“ File: {submission_filename}\")\n",
    "print(f\"ğŸ“ Shape: {submission_df.shape}\")\n",
    "print(f\"ğŸ¯ Prediction Distribution:\")\n",
    "prediction_counts = submission_df['Transported'].value_counts()\n",
    "print(f\"   â€¢ Transported (True): {prediction_counts[True]:,} ({prediction_counts[True]/len(submission_df)*100:.1f}%)\")\n",
    "print(f\"   â€¢ Not Transported (False): {prediction_counts[False]:,} ({prediction_counts[False]/len(submission_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Submission Preview:\")\n",
    "print(\"-\" * 40)\n",
    "display(submission_df.head(10))\n",
    "\n",
    "print(\"\\nğŸ‰ SUBMISSION READY! Upload to Kaggle and see your score!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ’¾ Saving Our Work: Model Versioning & Artifacts\n",
    "\n",
    "## ğŸ—ï¸ Professional ML Workflow: Saving Everything\n",
    "\n",
    "A professional data scientist always saves:\n",
    "- **The trained model** for future predictions\n",
    "- **The preprocessing pipeline** to handle new data the same way\n",
    "- **Model metadata** (performance, parameters, etc.)\n",
    "- **Experiment tracking** with MLflow\n",
    "\n",
    "### ğŸ¯ Why This Matters:\n",
    "- **Reproducibility**: You or others can reproduce your work\n",
    "- **Deployment**: Ready to use in applications\n",
    "- **Iteration**: Build upon your work later\n",
    "\n",
    "> ğŸ“š **Best Practice**: Always version your models and keep detailed documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ Save everything for future use\n",
    "print(\"ğŸ’¾ SAVING MODEL ARTIFACTS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create versioned model directory\n",
    "model_version = f\"champion_v1_{timestamp}\"\n",
    "model_save_dir = os.path.join(config.MODEL_DIR, model_version)\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ Creating model directory: {model_save_dir}\")\n",
    "\n",
    "# 1. Save the trained model\n",
    "model_path = os.path.join(model_save_dir, 'spaceship_model.pkl')\n",
    "joblib.dump(final_champion, model_path)\n",
    "print(f\"âœ… Model saved: {model_path}\")\n",
    "\n",
    "# 2. Save the preprocessing pipeline\n",
    "pipeline_path = os.path.join(model_save_dir, 'preprocessing_pipeline.pkl')\n",
    "joblib.dump(full_pipeline, pipeline_path)\n",
    "print(f\"âœ… Preprocessing pipeline saved: {pipeline_path}\")\n",
    "\n",
    "# 3. Create and save model card (metadata)\n",
    "model_card = {\n",
    "    'model_name': ultimate_champion_name,\n",
    "    'model_version': model_version,\n",
    "    'timestamp': timestamp,\n",
    "    'dataset': 'Spaceship Titanic',\n",
    "    'task': 'Binary Classification',\n",
    "    'target': 'Transported',\n",
    "    'author': 'Data Science Student',\n",
    "    \n",
    'performance': {\n",
    "        'test_accuracy': float(test_accuracy),\n",
    "        'test_precision': float(test_precision),\n",
    "        'test_recall': float(test_recall),\n",
    "        'test_f1': float(test_f1),\n",
    "        'test_roc_auc': float(test_roc_auc),\n",
    "        'val_accuracy': float(final_results[ultimate_champion_name]['val_accuracy']),\n",
    "        'baseline_accuracy': float(baseline_accuracy),\n",
    "        'improvement_over_baseline': float(improvement_over_baseline)\n",
    "    },\n",
    "    \n",
    "    'data_info': {\n",
    "        'train_samples': int(len(X_full_train)),\n",
    "        'test_samples': int(len(test_processed)),\n",
    "        'n_features': X_full_train.shape[1],\n",
    "        'feature_engineer': 'SpaceshipDetective',\n",
    "        'new_features_created': len([f for f in detective.get_feature_names() if f not in X.columns])\n",
    "    },\n",
    "    \n",
    "    'model_config': {\n",
    "        'model_class': ultimate_champion_name,\n",
    "        'hyperparameters': dict(final_champion.get_params()),\n",
    "    },\n",
    "    \n",
    "    'preprocessing': {\n",
    "        'steps': [\n",
    "            'SpaceshipDetective (advanced feature engineering)',\n",
    "            'Numerical imputation (median) + Robust scaling',\n",
    "            'Categorical imputation (mode) + One-hot encoding',\n",
    "        ],\n",
    "        'numerical_features': len(numerical_features),\n",
    "        'categorical_features': len(categorical_features)\n",
    "    },\n",
    "    \n",
    "    'kaggle_submission': {\n",
    "        'file': submission_filename,\n",
    "        'path': submission_path,\n",
    "        'prediction_distribution': submission_df['Transported'].value_counts().to_dict(),\n",
    "    },\n",
    "    \n",
    "    'training_info': {\n",
    "        'models_tested': len(model_team),\n",
    "        'best_model': ultimate_champion_name,\n",
    "        'tuning_improvement': float(final_results[ultimate_champion_name]['improvement']),\n",
    "        'experiment_tracking': f\"mlflow ui --backend-store-uri {config.EXPERIMENT_DIR}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save model card\n",
    "card_path = os.path.join(model_save_dir, 'model_card.json')\n",
    "with open(card_path, 'w') as f:\n",
    "    json.dump(model_card, f, indent=2)\n",
    "print(f\"âœ… Model card saved: {card_path}\")\n",
    "\n",
    "# 4. Save requirements\n",
    "requirements = {\n",
    "    'python': '3.8+',\n",
    "    'packages': {\n",
    "        'scikit-learn': '1.0+',\n",
    "        'pandas': '1.3+',\n",
    "        'numpy': '1.20+',\n",
    "        'mlflow': '2.0+',\n",
    "        'joblib': '1.0+',\n",
    "    }\n",
    "}\n",
    "\n",
    "req_path = os.path.join(model_save_dir, 'requirements.json')\n",
    "with open(req_path, 'w') as f:\n",
    "    json.dump(requirements, f, indent=2)\n",
    "print(f\"âœ… Requirements saved: {req_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ALL ARTIFACTS SAVED SUCCESSFULLY!\")\n",
    "print(\"\\nğŸ“š YOUR SAVED WORK:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   â€¢ Trained Model: {model_path}\")\n",
    "print(f\"   â€¢ Preprocessing Pipeline: {pipeline_path}\")\n",
    "print(f\"   â€¢ Model Card: {card_path}\")\n",
    "print(f\"   â€¢ Kaggle Submission: {submission_path}\")\n",
    "print(f\"   â€¢ Experiment Tracking: mlflow ui --backend-store-uri {config.EXPERIMENT_DIR}\")\n",
    "\n",
    "print(f\"\\nğŸš€ MISSION ACCOMPLISHED! You're ready for Kaggle!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¨ Bonus: Simple Prediction Interface\n",
    "\n",
    "## ğŸ”® Let's Create a Fun Prediction Tool!\n",
    "\n",
    "This simple interface lets you make predictions for new passengers. It's like having your own spaceship transportation predictor!\n",
    "\n",
    "> ğŸ® **Fun Exercise**: Try different passenger profiles and see if they'd be transported!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceshipPredictor:\n",
    "    \"\"\"\n",
    "    ğŸš€ Simple interface for making passenger transportation predictions\n",
    "    \n",
    "    This class uses our trained model to predict whether new passengers\n",
    "    would be transported based on their characteristics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, pipeline):\n",
    "        self.model = model\n",
    "        self.pipeline = pipeline\n",
    "    \n",
    "    def predict_passenger(self, passenger_data):\n",
    "        \"\"\"Predict transportation for a single passenger\"\"\"\n",
    "        \n",
    "        # Convert to DataFrame with proper column names\n",
    "        passenger_df = pd.DataFrame([passenger_data])\n",
    "        \n",
    "        # Apply preprocessing pipeline\n",
    "        processed_data = self.pipeline.transform(passenger_df)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(processed_data)[0]\n",
    "        probability = self.model.predict_proba(processed_data)[0]\n",
    "        \n",
    "        return {\n",
    "            'transported': bool(prediction),\n",
    "            'probability_transported': probability[1],\n",
    "            'probability_not_transported': probability[0],\n",
    "            'confidence': max(probability)\n",
    "        }\n",
    "    \n",
    "    def predict_multiple(self, passengers_data):\n",
    "        \"\"\"Predict transportation for multiple passengers\"\"\"\n",
    "        passengers_df = pd.DataFrame(passengers_data)\n",
    "        processed_data = self.pipeline.transform(passengers_df)\n",
    "        \n",
    "        predictions = self.model.predict(processed_data)\n",
    "        probabilities = self.model.predict_proba(processed_data)\n",
    "        \n",
    "        results = []\n",
    "        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "            results.append({\n",
    "                'passenger_id': i + 1,\n",
    "                'transported': bool(pred),\n",
    "                'probability_transported': prob[1],\n",
    "                'confidence': max(prob)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ğŸš€ Initialize our predictor\n",
    "predictor = SpaceshipPredictor(final_champion, full_pipeline)\n",
    "\n",
    "print(\"ğŸ¨ SPACESHIP TITANIC PREDICTION INTERFACE\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ”® Try our trained model with example passengers!\\n\")\n",
    "\n",
    "# Example passenger profiles\n",
    "example_passengers = [\n",
    "    {\n",
    "        'PassengerId': '0001_01',\n",
    "        'HomePlanet': 'Earth',\n",
    "        'CryoSleep': True,\n",
    "        'Cabin': 'B/123/P',\n",
    "        'Destination': 'TRAPPIST-1e',\n",
    "        'Age': 25,\n",
    "        'VIP': False,\n",
    "        'RoomService': 0,\n",
    "        'FoodCourt': 0,\n",
    "        'ShoppingMall': 0,\n",
    "        'Spa': 0,\n",
    "        'VRDeck': 0,\n",
    "        'Name': 'John Spacewalker'\n",
    "    },\n",
    "    {\n",
    "        'PassengerId': '0002_01',\n",
    "        'HomePlanet': 'Europa',\n",
    "        'CryoSleep': False,\n",
    "        'Cabin': 'A/001/S',\n",
    "        'Destination': '55 Cancri e',\n",
    "        'Age': 45,\n",
    "        'VIP': True,\n",
    "        'RoomService': 1000,\n",
    "        'FoodCourt': 500,\n",
    "        'ShoppingMall': 300,\n",
    "        'Spa': 800,\n",
    "        'VRDeck': 600,\n",
    "        'Name': 'Dr. Stella Stargazer'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Make predictions for examples\n",
    "print(\"ğŸ“Š EXAMPLE PREDICTIONS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, passenger in enumerate(example_passengers):\n",
    "    result = predictor.predict_passenger(passenger)\n",
    "    \n",
    "    print(f\"\\nğŸ‘¤ Passenger {i+1}: {passenger['Name']}\")\n",
    "    print(f\"   ğŸŒ Home Planet: {passenger['HomePlanet']}\")\n",
    "    print(f\"   ğŸ˜´ CryoSleep: {passenger['CryoSleep']}\")\n",
    "    print(f\"   ğŸ¯ Destination: {passenger['Destination']}\")\n",
    "    print(f\"   ğŸ‘‘ VIP: {passenger['VIP']}\")\n",
    "    \n",
    "    transport_status = \"ğŸš€ TRANSPORTED\" if result['transported'] else \"âŒ NOT TRANSPORTED\"\n",
    "    confidence_color = \"ğŸŸ¢\" if result['confidence'] > 0.8 else \"ğŸŸ¡\" if result['confidence'] > 0.6 else \"ğŸ”´\"\n",
    "    \n",
    "    print(f\"\\n   ğŸ”® PREDICTION: {transport_status}\")\n",
    "    print(f\"   ğŸ“Š Confidence: {confidence_color} {result['confidence']:.1%}\")\n",
    "    print(f\"   ğŸ“ˆ Probability: {result['probability_transported']:.1%} transported, {result['probability_not_transported']:.1%} not transported\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ‰ PREDICTION INTERFACE READY!\")\n",
    "print(\"ğŸ’¡ You can use the predictor class in your own applications!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‰ Congratulations! Mission Accomplished! ğŸ‰\n",
    "\n",
    "## ğŸŒŸ What You've Achieved:\n",
    "\n",
    "### ğŸ† Your Accomplishments:\n",
    "1. **âœ… Complete Data Investigation**: You explored and understood the Spaceship Titanic dataset\n",
    "2. **âœ… Advanced Feature Engineering**: Created powerful new features from raw data\n",
    "3. **âœ… Professional Preprocessing**: Built a robust pipeline that handles real-world data issues\n",
    "4. **âœ… Comprehensive Model Training**: Tested multiple algorithms and selected the best one\n",
    "5. **âœ… Hyperparameter Optimization**: Fine-tuned your model for peak performance\n",
    "6. **âœ… Rigorous Evaluation**: Properly validated your model using train/val/test splits\n",
    "7. **âœ… Kaggle-Ready Submission**: Created a properly formatted competition submission\n",
    "8. **âœ… Production Artifacts**: Saved everything needed for deployment\n",
    "\n",
    "### ğŸ“Š Your Model's Performance:\n",
    f\"\"\"\n",
    "- **Test Accuracy**: {test_accuracy:.1%}\n",
    "- **Improvement over Baseline**: +{improvement_over_baseline:.1%}\n",
    "- **Final Model**: {ultimate_champion_name}\n",
    "- **Submission File**: {submission_filename}\n",
    \"\"\"\n",
    "\n",
    "## ğŸš€ Next Steps:\n",
    "\n",
    "1. **ğŸ“¤ Submit to Kaggle**: Upload your CSV file to the competition and see your score!\n",
    "2. **ğŸ“Š Analyze Results**: Check the leaderboard and see how you compare\n",
    "3. **ğŸ”„ Iterate and Improve**: Try different features, models, or tuning strategies\n",
    "4. **ğŸ¤ Share Your Work**: Discuss your approach with the community\n",
    "\n",
    "### ğŸ’¡ Pro Tips for Improvement:\n",
    "- **Feature Engineering**: Create even more creative features\n",
    "- **Model Ensembles**: Combine multiple models for better performance\n",
    "- **Advanced Tuning**: Use more sophisticated hyperparameter optimization\n",
    "- **Cross-Validation**: Try different validation strategies\n",
    "\n",
    "## ğŸ¯ Key Lessons Learned:\n",
    "\n",
    "| Concept | Why It Matters |\n",
    "|---------|----------------|\n",
    "| **Data Exploration** | Understanding your data is the first step to good models |\n",
    "| **Feature Engineering** | Creative features can dramatically improve performance |\n",
    "| **Pipeline Construction** | Professional workflows prevent errors and save time |\n",
    "| **Model Evaluation** | Proper validation ensures your model actually works |\n",
    "| **Hyperparameter Tuning** | Small adjustments can lead to big improvements |\n",
    "| **Experiment Tracking** | MLflow helps you organize and reproduce your work |\n",
    "\n",
    "> ğŸŒŸ **You're now equipped with professional ML skills that apply to ANY classification problem!**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† Final Mission Debrief:\n",
    "\n",
    "You started as a space detective investigating the Spaceship Titanic mystery. Through careful analysis, creative feature engineering, and rigorous model testing, you've built a powerful predictor that can determine which passengers were transported to another dimension!\n",
    "\n",
    "**Your mission is complete, but the journey continues!** ğŸš€\n",
    "\n",
    "### ğŸ“š Resources to Continue Your Journey:\n",
    "- **Kaggle Competition**: [Spaceship Titanic](https://www.kaggle.com/competitions/spaceship-titanic)\n",
    "- **MLflow Documentation**: Learn more about experiment tracking\n",
    "- **Scikit-learn Guide**: Deep dive into machine learning algorithms\n",
    "- **Feature Engineering Books**: Master the art of creating great features\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŠ WELL DONE, DATA SCIENTIST! ğŸŠ\n",
    "\n",
    "You've successfully completed your first interstellar machine learning mission! The skills you've learned here will serve you well in any data science project you undertake.\n",
    "\n",
    "**Now go forth and predict!** ğŸŒŒ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}